{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCC",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwFIUOf1BkPs55SG43QAGq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sytrinh/digit_recognition_mnist/blob/main/FCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train a model to correctly identify digits from 0 to 9 using the MNIST dataset. The model consists of fully connected layers and is trained using:\n",
        "1. Keras\n",
        "2. Only TensorFlow"
      ],
      "metadata": {
        "id": "DFGK6oStawd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "2FGange9sfl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understand and preprocess the data"
      ],
      "metadata": {
        "id": "9wPlH4qgwP1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "unique_labels = np.unique(train_labels)\n",
        "\n",
        "print('Training set shape: {}'.format(train_images.shape))\n",
        "print('Test set shape: {}'.format(test_images.shape))\n",
        "print('Number of images in training set: {}'.format(train_images.shape[0]))\n",
        "print('Number of images in test set: {}'.format(test_images.shape[0]))\n",
        "print('Image size: {}'.format(train_images.shape[1:]))\n",
        "print('Unique labels: {}'.format(unique_labels))\n",
        "print('Number of unique labels: {}'.format(len(np.unique(train_labels))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IHk0qa3wFPU",
        "outputId": "2d11e0fe-451d-47e2-8d8e-eec934c294f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (60000, 28, 28)\n",
            "Test set shape: (10000, 28, 28)\n",
            "Number of images in training set: 60000\n",
            "Number of images in test set: 10000\n",
            "Image size: (28, 28)\n",
            "Unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "Number of unique labels: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_idx = 10\n",
        "image = train_images[img_idx]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "print('Corresponding label: {}'.format(train_labels[img_idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gohYMAdLuY2U",
        "outputId": "39ea3c42-f994-42a7-8576-a3295956e634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corresponding label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're going to use a neural network with fully connected layers (FCL), images need to be reshaped to become a 1D array. As a result, training set will become a 2D array of size `(examples, width*height)`. We should also scale the data so that all values are in the `[0,1]` interval. "
      ],
      "metadata": {
        "id": "zTV7dSxU0x_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_images.reshape((train_images.shape[0], -1))\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = test_images.reshape((test_images.shape[0], -1))\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "print('x_train shape: {}'.format(x_train.shape))\n",
        "print('x_test shape: {}'.format(x_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Z0xDhuydjS",
        "outputId": "8c2c3f00-58ea-4a17-965b-435c4d46a6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 784)\n",
            "x_test shape: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_labels\n",
        "y_test = test_labels"
      ],
      "metadata": {
        "id": "lvtj7D462jUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model using Keras"
      ],
      "metadata": {
        "id": "_9nLbzvQ6wZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          layers.Dense(512, activation='relu'),\n",
        "                          layers.Dense(10, activation='softmax')])\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)  # Gradient descent (with momentum) optimizer.\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs=10, batch_size=128, verbose=1)"
      ],
      "metadata": {
        "id": "Dh-cdvuS5216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18159ffb-0cab-48e7-f30c-0bcaf8a12222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 2.0936 - accuracy: 0.3594\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.6864 - accuracy: 0.6755\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.3812 - accuracy: 0.7494\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.1587 - accuracy: 0.7837\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.0005 - accuracy: 0.8065\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8867 - accuracy: 0.8214\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8026 - accuracy: 0.8322\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7384 - accuracy: 0.8407\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6881 - accuracy: 0.8480\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6476 - accuracy: 0.8533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == y_test\n",
        "print(f\"Test accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhz3jfqbCjgJ",
        "outputId": "11464e2c-81a0-452b-fe74-7839dd352b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model using only Tensorflow"
      ],
      "metadata": {
        "id": "t_NIVg30FnjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "  \"\"\"\n",
        "  Generate mini-batches\n",
        "  \"\"\"\n",
        "  def __init__(self, x, y, batch_size=128):\n",
        "    assert len(x) == len(y)\n",
        "    self.index = 0\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.batch_size = batch_size\n",
        "    self.num_batches = math.ceil(len(x)/batch_size)\n",
        "\n",
        "  def next(self):\n",
        "    x = self.x[self.index:self.index+self.batch_size]\n",
        "    y = self.y[self.index:self.index+self.batch_size]\n",
        "    self.index += self.batch_size\n",
        "    return x, y\n",
        "\n",
        "#------------------------------------------------------------\n",
        "\n",
        "\n",
        "class MyDense:\n",
        "\n",
        "  def __init__(self, n_nodes, activation):\n",
        "    self.n_nodes = n_nodes\n",
        "    self.activation = activation\n",
        "    self.W = None\n",
        "    self.b = None\n",
        "\n",
        "  def initialize_weights(self, input_size):\n",
        "    output_size = self.n_nodes\n",
        "    w_shape = (input_size, output_size)\n",
        "    w_init = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "    self.W = tf.Variable(w_init)\n",
        "\n",
        "    b_shape = (output_size,)\n",
        "    b_init = tf.zeros(b_shape)\n",
        "    self.b = tf.Variable(b_init)\n",
        "\n",
        "  @tf.function\n",
        "  def forward(self, inputs):\n",
        "    return self.activation(tf.matmul(inputs, self.W)+self.b)\n",
        "\n",
        "  @property  # return an tensorflow objects of properties\n",
        "  def weights(self):\n",
        "    return [self.W, self.b] \n",
        "\n",
        "  def output_size(self):\n",
        "    return self.n_nodes\n",
        "\n",
        "#------------------------------------------------------------\n",
        "\n",
        "class MyModel:\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers # a list of layer class instances, MyDense in this case\n",
        "    self.loss_function = None\n",
        "    self.learning_rate = None\n",
        "    self.weights = None\n",
        "  \n",
        "  def compile(self, loss_function, learning_rate, nn_input_size):\n",
        "    \"\"\"\n",
        "    Initialize weights for each layer\n",
        "    Automatically use the output_size of the previous layer as the input_size\n",
        "    \"\"\"\n",
        "    self.loss_function = loss_function\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    input_size = nn_input_size\n",
        "    for layer in self.layers:\n",
        "      layer.initialize_weights(input_size)\n",
        "      input_size = layer.output_size()\n",
        "\n",
        "    # Combine all the weights\n",
        "    self.weights = []\n",
        "    for layer in self.layers:\n",
        "      self.weights += layer.weights\n",
        "\n",
        "  # forward propagation through the network\n",
        "  def predict(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.layers:\n",
        "      x = layer.forward(x)\n",
        "    return x\n",
        "\n",
        "  @tf.function\n",
        "  def one_batch_training(self, x_batch, y_batch):\n",
        "    # Forward propagation\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.predict(x_batch)\n",
        "      per_sample_losses = self.loss_function(y_batch, predictions)\n",
        "      average_loss = tf.reduce_mean(per_sample_losses)\n",
        "\n",
        "    # Backward propagation\n",
        "    gradients = tape.gradient(average_loss, self.weights)\n",
        "    # Update weights using gradient descent\n",
        "    for g, w in zip(gradients, self.weights):\n",
        "      w.assign_sub(g*self.learning_rate)\n",
        "    \n",
        "    return average_loss\n",
        "\n",
        "  def fit(self, x, y, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "      # print(f\"Epoch {epoch_counter}\")\n",
        "      batch_generator = BatchGenerator(x, y, batch_size)\n",
        "\n",
        "      for batch_counter in range(batch_generator.num_batches):\n",
        "        x_batch, y_batch = batch_generator.next()\n",
        "        loss = self.one_batch_training(x_batch, y_batch)\n",
        "        if batch_counter == batch_generator.num_batches-1:\n",
        "          print(f\"Epoch {epoch_counter}/{epochs} - loss: {loss:.2f}\")\n",
        "          # print(f\"loss at batch {batch_counter}: {loss:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TGdXS08EFvAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel([\n",
        "                 MyDense(512, activation=tf.nn.relu),\n",
        "                 MyDense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(tf.keras.metrics.sparse_categorical_crossentropy,\n",
        "              learning_rate=1e-3, \n",
        "              nn_input_size=28*28)\n",
        "\n",
        "history = model.fit(x_train, y_train, \n",
        "                    epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilBD9xzi36x6",
        "outputId": "5edf3b40-93e0-4184-edf3-a06f8f07a0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/10 - loss: 2.01\n",
            "Epoch 1/10 - loss: 1.75\n",
            "Epoch 2/10 - loss: 1.53\n",
            "Epoch 3/10 - loss: 1.35\n",
            "Epoch 4/10 - loss: 1.20\n",
            "Epoch 5/10 - loss: 1.09\n",
            "Epoch 6/10 - loss: 0.99\n",
            "Epoch 7/10 - loss: 0.92\n",
            "Epoch 8/10 - loss: 0.86\n",
            "Epoch 9/10 - loss: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == y_test\n",
        "print(f\"Test accuracy: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMTibMbRBKnn",
        "outputId": "e8af8a05-4a4b-44ad-de55-ccf97df7fac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments\n",
        "\n",
        "Our implementation using only Tensorflow is worse than using Keras. The main reason is:\n",
        "- The optimizer SGD in keras is gradient descent with momentum\n",
        "- In the Tensorflow implementation, we only use the simple gradient descent algorithm (without momentum)."
      ],
      "metadata": {
        "id": "VCUyNBuRPkyW"
      }
    }
  ]
}